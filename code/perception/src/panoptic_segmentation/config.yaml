MODEL:
  ANCHOR_GENERATOR:
    SIZES: [ [ 32 ], [ 64 ], [ 128 ], [ 256 ] ]  # One size for each in feature map
    ASPECT_RATIOS: [ [ 0.5, 1.0, 2.0 ] ]  # Three aspect ratios (same for all in feature maps)
  PROPOSAL_GENERATOR:
    NAME: "RPNCustom"
  RPN:
    HEAD_NAME: "DepthwiseSepRPNHead" # Normal RPN Head "StandardRPNHead"
    IN_FEATURES: [ "P_4", "P_8", "P_16", "P_32" ]
    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
    PRE_NMS_TOPK_TEST: 2000  # Per FPN level
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    BBOX_REG_LOSS_WEIGHT: 1.0
    SMOOTH_L1_BETA: 0.11111111 # 1.0 / 9.0

    # Detectron1 uses 2000 proposals per-batch,
    # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 1000
    SMOOTH_L1_BETA: 0.1111
    IOU_THRESHOLDS: [ 0.3, 0.7 ]
  ROI_HEADS:
    NAME: "CustomROIHeads"
    # BATCH_SIZE_PER_IMAGE: 256 # number of proposals to sample for training
    # POSITIVE_FRACTION: 0.25 # fraction of positive (foreground) proposals to sample for training.
    IN_FEATURES: [ "P_4", "P_8", "P_16", "P_32" ]
    NUM_CLASSES: 14 # There is 14 instance in our dataset
    # PROPOSAL_APPEND_GT:
    IOU_THRESHOLDS: [ 0.5 ]
    # IOU_LABELS:
    SCORE_THRESH_TEST: 0.5 # First step of panoptic fusion module
    NMS_THRESH_TEST: 0.5 # Second step of panoptic fusion module
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2 # (maybe put to 2) The `sampling_ratio` parameter for the ROIAlign op.
    POOLER_TYPE: "ROIAlign" # "ROIAlignV2"
    SMOOTH_L1_BETA: 1.0
    # SCORE_THRESH_TEST: 0.05
    # NMS_THRESH_TEST: 0.5
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    SMOOTH_L1_BETA: 1.0
    BBOX_REG_LOSS_WEIGHT: 1.0
  ROI_MASK_HEAD:
    POOLER_RESOLUTION: 14
    POOLER_TYPE: "ROIAlign"
TEST:
  DETECTIONS_PER_IMAGE: 100

#### CUSTOM PARAMETER  #####

# DATA
# Path to cityscapes dataset
DATASET_PATH: "/workspace/code/output/leaderboard_dataset_converted/"
TRAIN_JSON: "groundtruth/panoptic_train.json"
VALID_JSON: "groundtruth/panoptic_val.json"
PRED_DIR: "preds" # Path of images generated in the dataset folder
PRED_JSON: "cityscapes_panoptic_preds.json" # Path in the dataset folder of the prediction json created

# TRANSFORM based on albumentation https://albumentations.ai/
TRANSFORM:
  NORMALIZE:
    MEAN: (0.485, 0.456, 0.406)
    STD: (0.229, 0.224, 0.225)
  RESIZE:
    HEIGHT: 512
    WIDTH: 1024
  RANDOMCROP:
    HEIGHT: 512
    WIDTH: 1024
  HFLIP:
    PROB: 0.5

# Solver
SOLVER:
  NAME: "Adam" # Adam or SGD
  BASE_LR: 1.3e-3
  WEIGHT_DECAY: 0.0001 # Only for SGD
  WARMUP_ITERS: 500 # Set to 0 for no warmup
  ACCUMULATE_GRAD: 1 # Number of accumulated epochs for accumulated gradient

CALLBACKS:
  CHECKPOINT_DIR: "logs/test-10-patience"

# Path to load a model
CHECKPOINT_PATH: ""
BATCH_SIZE: 1
PRECISION: 16 # Bit precision for mix precision training
NUM_CLASS: 15
MODEL_CUSTOM:
  BACKBONE:
    EFFICIENTNET_ID: 5 # Id of the EfficienNet model
    LOAD_PRETRAIN: True # Load pretrained EfficienNet model
INFERENCE:
  AREA_TRESH: 512 #1024 / 2 because it's made on image of resize size
